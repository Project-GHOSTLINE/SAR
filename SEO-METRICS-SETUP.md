# üìä SEO Metrics System - Guide de Configuration

**Projet**: Solution Argent Rapide (SAR)
**Date**: 2026-01-21
**Objectif**: Enregistrer et analyser toutes les m√©triques SEO dans Supabase

---

## ‚úÖ Ce qui a √©t√© cr√©√©

### 1. Migration SQL (`supabase/migrations/20260121000000_seo_metrics_system.sql`)

**6 Tables cr√©√©es**:
- `seo_ga4_metrics_daily` - M√©triques Google Analytics 4 (quotidiennes)
- `seo_gsc_metrics_daily` - M√©triques Google Search Console (quotidiennes)
- `seo_semrush_domain_daily` - M√©triques Semrush (quotidiennes)
- `seo_keywords_tracking` - Suivi des mots-cl√©s strat√©giques
- `seo_audit_log` - Journal des audits et probl√®mes SEO
- `seo_collection_jobs` - Historique des jobs de collecte

**3 Vues cr√©√©es**:
- `seo_summary_30d` - R√©sum√© des 30 derniers jours
- `seo_top_keywords` - Top keywords performance
- `seo_pending_issues` - Issues √† r√©soudre

**Fonctionnalit√©s**:
- ‚úÖ Triggers automatiques pour `updated_at`
- ‚úÖ Calcul automatique des changements de position
- ‚úÖ RLS (Row Level Security) activ√©
- ‚úÖ Indexes pour performances
- ‚úÖ 8 keywords strat√©giques pr√©-configur√©s

### 2. API Endpoints

#### Collecte des donn√©es
- **POST** `/api/seo/collect/ga4` - Collecter m√©triques GA4
- **POST** `/api/seo/collect/gsc` - Collecter m√©triques Google Search Console
- **POST** `/api/seo/collect/semrush` - Collecter m√©triques Semrush

#### R√©cup√©ration des donn√©es
- **GET** `/api/seo/collect/ga4?startDate=YYYY-MM-DD&endDate=YYYY-MM-DD` - Historique GA4
- **GET** `/api/seo/collect/gsc?startDate=YYYY-MM-DD&endDate=YYYY-MM-DD` - Historique GSC
- **GET** `/api/seo/collect/semrush?startDate=YYYY-MM-DD&endDate=YYYY-MM-DD` - Historique Semrush
- **GET** `/api/seo/metrics?period=30d&source=all` - R√©sum√© complet

#### Gestion des keywords
- **GET** `/api/seo/keywords` - Liste des keywords
- **POST** `/api/seo/keywords` - Ajouter un keyword
- **PATCH** `/api/seo/keywords` - Mettre √† jour un keyword
- **DELETE** `/api/seo/keywords` - D√©sactiver un keyword

#### Cron job automatique
- **GET** `/api/cron/seo-collect` - Collecte automatique quotidienne

---

## üöÄ √âtapes d'Installation

### √âtape 1: Appliquer la Migration SQL

**Option A: Via Supabase Dashboard (RECOMMAND√â)**

1. Ouvrir: https://supabase.com/dashboard/project/dllyzfuqjzuhvshrlmuq/editor
2. Cliquer sur **"SQL Editor"** dans la sidebar
3. Cliquer sur **"New Query"**
4. Copier-coller le contenu de: `supabase/migrations/20260121000000_seo_metrics_system.sql`
5. Cliquer sur **"Run"** (ou Ctrl+Enter)
6. V√©rifier le message: `‚úÖ SEO Metrics System: Toutes les tables cr√©√©es avec succ√®s (6/6)`

**Option B: Via Script**

```bash
cd /Users/xunit/Desktop/üìÅ\ Projets/sar
./scripts/apply-seo-migration.sh
```

### √âtape 2: V√©rifier les Tables

Dans Supabase Dashboard ‚Üí Table Editor, vous devriez voir:

- ‚úÖ `seo_ga4_metrics_daily` (0 rows)
- ‚úÖ `seo_gsc_metrics_daily` (0 rows)
- ‚úÖ `seo_semrush_domain_daily` (0 rows)
- ‚úÖ `seo_keywords_tracking` (8 rows - keywords pr√©-configur√©s)
- ‚úÖ `seo_audit_log` (0 rows)
- ‚úÖ `seo_collection_jobs` (0 rows)

### √âtape 3: Configurer les Credentials

Ajouter dans `.env.local`:

```env
# Google Analytics 4 (D√âJ√Ä CONFIGUR√â ‚úÖ)
NEXT_PUBLIC_GA_MEASUREMENT_ID=G-F130RBTZDC
GA_PROPERTY_ID=340237010

# Google Search Console (√Ä CONFIGURER)
GOOGLE_SERVICE_ACCOUNT_EMAIL=xxx@xxx.iam.gserviceaccount.com
GOOGLE_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n"
GOOGLE_PROJECT_ID=votre-project-id
GSC_SITE_URL=https://solutionargentrapide.ca

# Semrush API (√Ä CONFIGURER)
SEMRUSH_API_KEY=votre-semrush-api-key
SEMRUSH_API_URL=https://api.semrush.com/

# Cron Secret
CRON_SECRET=cron-secret-sar-2026
```

### √âtape 4: Configurer le Cron Job dans Vercel

1. Ouvrir: https://vercel.com/project-ghostline/sar/settings/cron-jobs
2. Cliquer sur **"Add Cron Job"**
3. Configurer:
   - **Name**: SEO Daily Collection
   - **Path**: `/api/cron/seo-collect`
   - **Schedule**: `0 6 * * *` (tous les jours √† 6h UTC = 2h EST)
   - **HTTP Method**: GET
   - **Headers**:
     - `authorization: Bearer cron-secret-sar-2026`
4. Sauvegarder

### √âtape 5: Tester la Collecte

**Test manuel GA4**:
```bash
curl -X POST https://admin.solutionargentrapide.ca/api/seo/collect/ga4 \
  -H "x-api-key: FredRosa%1978" \
  -H "Content-Type: application/json"
```

**Test manuel GSC**:
```bash
curl -X POST https://admin.solutionargentrapide.ca/api/seo/collect/gsc \
  -H "x-api-key: FredRosa%1978" \
  -H "Content-Type: application/json"
```

**Test manuel Semrush**:
```bash
curl -X POST https://admin.solutionargentrapide.ca/api/seo/collect/semrush \
  -H "x-api-key: FredRosa%1978" \
  -H "Content-Type: application/json"
```

**R√©cup√©rer les m√©triques**:
```bash
curl "https://admin.solutionargentrapide.ca/api/seo/metrics?period=30d" \
  -H "x-api-key: FredRosa%1978"
```

**Tester le cron job**:
```bash
curl "https://admin.solutionargentrapide.ca/api/cron/seo-collect" \
  -H "authorization: Bearer cron-secret-sar-2026"
```

---

## üìä Utilisation

### Collecter les M√©triques Manuellement

```bash
# Collecter pour une date sp√©cifique
curl -X POST https://admin.solutionargentrapide.ca/api/seo/collect/ga4 \
  -H "x-api-key: FredRosa%1978" \
  -H "Content-Type: application/json" \
  -d '{"date": "2026-01-20", "force": true}'
```

### R√©cup√©rer un R√©sum√© Complet

```bash
# R√©sum√© 30 derniers jours
curl "https://admin.solutionargentrapide.ca/api/seo/metrics?period=30d&source=all" \
  -H "x-api-key: FredRosa%1978"
```

### G√©rer les Keywords

**Ajouter un keyword**:
```bash
curl -X POST https://admin.solutionargentrapide.ca/api/seo/keywords \
  -H "x-api-key: FredRosa%1978" \
  -H "Content-Type: application/json" \
  -d '{
    "keyword": "pr√™t urgent",
    "category": "pr√™t",
    "priority": "high",
    "search_volume": 590,
    "target_url": "https://solutionargentrapide.ca"
  }'
```

**Lister les keywords**:
```bash
curl "https://admin.solutionargentrapide.ca/api/seo/keywords" \
  -H "x-api-key: FredRosa%1978"
```

**Mettre √† jour un keyword**:
```bash
curl -X PATCH https://admin.solutionargentrapide.ca/api/seo/keywords \
  -H "x-api-key: FredRosa%1978" \
  -H "Content-Type: application/json" \
  -d '{
    "id": "uuid-du-keyword",
    "current_position": 8,
    "previous_position": 12
  }'
```

---

## üìà Donn√©es Collect√©es

### Google Analytics 4
- Utilisateurs (total, nouveaux, actifs)
- Sessions (total, engag√©es, dur√©e moyenne)
- Taux d'engagement / bounce rate
- Conversions
- Traffic sources (organic, direct, referral, social, paid, email)
- Device breakdown (desktop, mobile, tablet)
- Top pages
- Top events

### Google Search Console
- Clics et impressions
- CTR (Click-through rate)
- Position moyenne
- Top queries (avec m√©triques d√©taill√©es)
- Top pages performantes
- Breakdown par device
- Donn√©es d'indexation

### Semrush
- Ranking du domaine
- Keywords organiques (nombre et positions)
- Traffic organique estim√©
- Backlinks (total, referring domains)
- Authority score
- Top keywords avec positions
- Concurrents principaux

### Keywords Tracking
- Position actuelle vs pr√©c√©dente
- Changement de position
- Search volume
- Difficult√©
- Historique des positions
- Traffic estim√©

---

## üîÑ Collecte Automatique

Le cron job `/api/cron/seo-collect` s'ex√©cute **tous les jours √† 6h UTC (2h EST)** et collecte:

1. ‚úÖ Google Analytics 4 (donn√©es de la veille)
2. ‚úÖ Google Search Console (donn√©es d'il y a 3 jours - d√©lai GSC)
3. ‚úÖ Semrush (donn√©es de la veille)

Les r√©sultats sont enregistr√©s dans `seo_collection_jobs` pour audit.

---

## üéØ Prochaines √âtapes

### Court terme (1-2 jours)
1. ‚úÖ Appliquer la migration SQL
2. ‚è≥ Configurer le cron job Vercel
3. ‚è≥ Tester la collecte manuelle
4. ‚è≥ V√©rifier la collecte automatique (attendre 24h)

### Moyen terme (1 semaine)
1. Configurer Google Search Console API (service account)
2. Configurer Semrush API (si budget disponible)
3. Cr√©er un dashboard admin pour visualiser les m√©triques
4. Ajouter plus de keywords √† suivre

### Long terme (1 mois)
1. Impl√©menter les audits SEO automatiques
2. Cr√©er des alertes pour changements importants
3. G√©n√©rer des rapports SEO hebdomadaires
4. Int√©grer avec n8n pour automatisations avanc√©es

---

## üÜò Troubleshooting

### La migration √©choue
- V√©rifier que vous utilisez le bon projet Supabase (dllyzfuqjzuhvshrlmuq)
- V√©rifier que vous avez les permissions admin
- Essayer via le Dashboard plut√¥t que CLI

### La collecte GA4 √©choue
- V√©rifier `GA_PROPERTY_ID=340237010` dans .env.local
- Pour l'instant, le syst√®me utilise des donn√©es mock si credentials manquants
- Configurer `GA_SERVICE_ACCOUNT_JSON` pour vraies donn√©es

### Le cron job ne s'ex√©cute pas
- V√©rifier la configuration dans Vercel
- V√©rifier que `CRON_SECRET` est d√©fini dans Vercel env vars
- V√©rifier les logs Vercel pour erreurs

### Pas de donn√©es dans les tables
- Normal au d√©but! Le cron job collectera automatiquement
- Tester manuellement avec les endpoints `/api/seo/collect/*`
- Attendre 24h pour la premi√®re collecte automatique

---

## üìû Support

- **Documentation Supabase**: https://supabase.com/docs
- **Documentation Vercel Cron**: https://vercel.com/docs/cron-jobs
- **Logs Vercel**: https://vercel.com/project-ghostline/sar/logs

---

**‚úÖ Syst√®me SEO Metrics pr√™t √† √™tre d√©ploy√©!**

*Derni√®re mise √† jour: 2026-01-21*
