/**
 * Script d'import des clients SAR depuis XLSX avec tra√ßage complet
 *
 * Pipeline:
 * 1. Lecture XLSX ‚Üí Validation ‚Üí Transformation ‚Üí Insertion Supabase
 * 2. Tra√ßage √† chaque √©tape
 * 3. V√©rifications de dataflow
 */

import * as fs from 'fs'
import * as path from 'path'
import { createClient } from '@supabase/supabase-js'
import { config } from 'dotenv'

// Charger les variables d'environnement
config({ path: path.join(process.cwd(), '.env.local') })

// ================== CONFIGURATION ==================
const xlsxFilePath = process.argv[2] || '/Users/xunit/Desktop/Margiil Files/liste-client-sar.xlsx'
const BATCH_SIZE = 100
const DRY_RUN = process.argv.includes('--dry-run')
const SKIP_DUPLICATES = process.argv.includes('--skip-duplicates')

// Variables d'environnement Supabase
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY!

if (!supabaseUrl || !supabaseKey) {
  console.error('‚ùå Variables d\'environnement Supabase manquantes')
  process.exit(1)
}

const supabase = createClient(supabaseUrl, supabaseKey)

// ================== TYPES ==================
interface ClientSAR {
  margill_id: string
  dossier_id?: string
  identifiant_unique_1?: string
  identifiant_unique_2?: string
  prenom?: string
  nom?: string
  nom_complet?: string
  date_naissance?: string
  nas?: string
  email?: string
  telephone?: string
  telephone_mobile?: string
  adresse_ligne1?: string
  adresse_ligne2?: string
  ville?: string
  province?: string
  code_postal?: string
  pays?: string
  employeur?: string
  telephone_employeur?: string
  date_embauche?: string
  occupation?: string
  personne_contact_employeur?: string
  contact1_nom?: string
  contact1_telephone?: string
  contact2_nom?: string
  contact2_telephone?: string
  banque_institution?: string
  banque_transit?: string
  banque_compte?: string
  capital_origine?: number
  montant_paiement?: number
  frequence_paiement?: string
  etat_dossier?: string
  responsable_dossier?: string
  date_creation_dossier?: string
  date_maj_dossier?: string
  total_paiements_positifs?: number
  total_paiements_negatifs?: number
  nombre_paiements_faits?: number
  nombre_paiements_non_payes?: number
  nombre_mauvaises_creances?: number
  solde_actuel?: number
  solde_capital_recevoir?: number
  date_premier_paiement?: string
  date_dernier_paiement?: string
  montant_dernier_paiement?: number
  etat_dernier_paiement?: string
  lien_ibv?: string
  flag_pas_ibv?: boolean
  flag_mauvaise_creance?: boolean
  flag_paiement_rate_precoce?: boolean
  flag_documents_email?: boolean
}

interface PipelineStats {
  step: string
  input: number
  output: number
  errors: number
  duration: number
  details?: any
}

// ================== TRA√áAGE PIPELINE ==================
const pipelineTrace: PipelineStats[] = []

function logPipelineStep(step: string, input: number, output: number, errors: number, startTime: number, details?: any) {
  const duration = Date.now() - startTime
  pipelineTrace.push({ step, input, output, errors, duration, details })

  const emoji = errors > 0 ? '‚ö†Ô∏è' : '‚úÖ'
  console.log(`\n${emoji} ${step}`)
  console.log(`   üì• Input: ${input}`)
  console.log(`   üì§ Output: ${output}`)
  if (errors > 0) console.log(`   ‚ùå Errors: ${errors}`)
  console.log(`   ‚è±Ô∏è  Duration: ${duration}ms`)
  if (details) {
    Object.keys(details).forEach(key => {
      console.log(`   üìä ${key}: ${JSON.stringify(details[key])}`)
    })
  }
}

// ================== UTILITAIRES ==================
function parseDate(dateStr: string | number): string | undefined {
  if (!dateStr) return undefined

  try {
    // Si c'est un nombre Excel (jours depuis 1900-01-01)
    if (typeof dateStr === 'number') {
      const excelEpoch = new Date(1899, 11, 30)
      const date = new Date(excelEpoch.getTime() + dateStr * 86400000)
      return date.toISOString().split('T')[0]
    }

    // Si c'est une cha√Æne
    const str = String(dateStr).trim()
    if (str === '') return undefined

    // Format YYYY-MM-DD
    if (/^\d{4}-\d{2}-\d{2}$/.test(str)) {
      return str
    }

    // Format MM-DD-YYYY ou DD-MM-YYYY
    const parts = str.split(/[-/]/)
    if (parts.length === 3) {
      const [a, b, c] = parts
      // Si ann√©e en premier
      if (a.length === 4) return `${a}-${b.padStart(2, '0')}-${c.padStart(2, '0')}`
      // Sinon on assume MM-DD-YYYY (format Margill)
      return `${c}-${a.padStart(2, '0')}-${b.padStart(2, '0')}`
    }
  } catch (e) {
    console.warn(`‚ö†Ô∏è  Date invalide: ${dateStr}`)
  }
  return undefined
}

function parseAmount(amount: string | number): number | undefined {
  if (!amount && amount !== 0) return undefined

  try {
    if (typeof amount === 'number') return amount

    const cleanAmount = String(amount).replace(/[$\s,]/g, '').trim()
    const parsed = parseFloat(cleanAmount)
    return isNaN(parsed) ? undefined : parsed
  } catch (e) {
    return undefined
  }
}

function parseInteger(int: string | number): number | undefined {
  if (!int && int !== 0) return undefined

  try {
    if (typeof int === 'number') return Math.floor(int)

    const parsed = parseInt(String(int), 10)
    return isNaN(parsed) ? undefined : parsed
  } catch (e) {
    return undefined
  }
}

// ================== LECTURE XLSX ==================
async function readXLSX(): Promise<any[]> {
  const startTime = Date.now()
  console.log('üìñ √âTAPE 1: Lecture du fichier XLSX...')
  console.log(`   üìÅ Fichier: ${xlsxFilePath}`)

  try {
    // Utiliser Python car xlsx n'est pas install√©
    const pythonScript = `
import openpyxl
import json
import sys

wb = openpyxl.load_workbook('${xlsxFilePath}', read_only=True, data_only=True)
ws = wb.active

# Lire le header
headers = [cell.value for cell in ws[1]]

# Lire toutes les lignes
data = []
for row in ws.iter_rows(min_row=2, values_only=True):
    row_dict = {}
    for idx, (header, value) in enumerate(zip(headers, row)):
        if header:
            row_dict[str(header)] = value
    if row_dict:
        data.append(row_dict)

print(json.dumps(data, default=str))
wb.close()
`

    fs.writeFileSync('/tmp/read-xlsx-import.py', pythonScript)

    const { execSync } = require('child_process')
    const output = execSync('python3 /tmp/read-xlsx-import.py', {
      maxBuffer: 50 * 1024 * 1024,
      encoding: 'utf-8'
    })

    const records = JSON.parse(output)

    logPipelineStep(
      'Lecture XLSX',
      records.length,
      records.length,
      0,
      startTime,
      {
        fileSize: fs.statSync(xlsxFilePath).size,
        fileName: path.basename(xlsxFilePath)
      }
    )

    return records
  } catch (error: any) {
    console.error('‚ùå Erreur lecture XLSX:', error.message)
    logPipelineStep('Lecture XLSX', 0, 0, 1, startTime, { error: error.message })
    throw error
  }
}

// ================== TRANSFORMATION ==================
function transformClient(row: any): ClientSAR | null {
  try {
    // Colonne 1: Margill ID (OBLIGATOIRE)
    const margillId = String(row['Emprunteur - Identifiant'] || '').trim()
    if (!margillId || margillId === '') {
      return null // Ligne invalide
    }

    // Construire le client
    const client: ClientSAR = {
      // Identifiants
      margill_id: margillId,
      dossier_id: row['Identification GPM du Dossier'] ? String(row['Identification GPM du Dossier']).trim() : undefined,
      identifiant_unique_1: row['Emprunteur - Identifiant unique 1'] ? String(row['Emprunteur - Identifiant unique 1']).trim() : undefined,
      identifiant_unique_2: row['Emprunteur - Identifiant unique 2'] ? String(row['Emprunteur - Identifiant unique 2']).trim() : undefined,

      // Informations personnelles
      prenom: row['Emprunteur - Pr√©nom'] ? String(row['Emprunteur - Pr√©nom']).trim() : undefined,
      nom: row['Emprunteur - Nom'] ? String(row['Emprunteur - Nom']).trim() : undefined,
      nom_complet: row['Emprunteur - Pr√©nom Nom'] ? String(row['Emprunteur - Pr√©nom Nom']).trim() : undefined,
      date_naissance: parseDate(row['Emprunteur - Date de naissance'] || row['Date de naissance client']),
      nas: row['Emprunteur - Num√©ro d\'assurance sociale'] ? String(row['Emprunteur - Num√©ro d\'assurance sociale']).trim() : undefined,

      // Contact
      email: row['Emprunteur - Courriel'] ? String(row['Emprunteur - Courriel']).trim().toLowerCase() : undefined,
      telephone: row['Emprunteur - Num√©ro de T√©l√©phone'] ? String(row['Emprunteur - Num√©ro de T√©l√©phone']).trim() : undefined,
      telephone_mobile: row['Emprunteur - Num√©ro de Mobile'] ? String(row['Emprunteur - Num√©ro de Mobile']).trim() : undefined,

      // Adresse
      adresse_ligne1: row['Emprunteur - Adresse 1'] ? String(row['Emprunteur - Adresse 1']).trim() : undefined,
      adresse_ligne2: row['Emprunteur - Adresse 2'] ? String(row['Emprunteur - Adresse 2']).trim() : undefined,
      ville: row['Emprunteur - Ville'] ? String(row['Emprunteur - Ville']).trim() : undefined,
      province: row['Emprunteur - Province, √âtat'] ? String(row['Emprunteur - Province, √âtat']).trim() : undefined,
      code_postal: row['Emprunteur - Code postal'] ? String(row['Emprunteur - Code postal']).trim() : undefined,
      pays: row['Emprunteur - Pays'] ? String(row['Emprunteur - Pays']).trim() : undefined,

      // Employeur
      employeur: row['Employeur'] ? String(row['Employeur']).trim() : undefined,
      telephone_employeur: row['T√©l√©phone de l\'employeur'] ? String(row['T√©l√©phone de l\'employeur']).trim() : undefined,
      date_embauche: parseDate(row['Date d\'embauche']),
      occupation: row['Emprunteur - Occupation'] ? String(row['Emprunteur - Occupation']).trim() : undefined,
      personne_contact_employeur: row['Personne √† contacter chez l\'employeur'] ? String(row['Personne √† contacter chez l\'employeur']).trim() : undefined,

      // Contacts
      contact1_nom: row['Contact 1'] ? String(row['Contact 1']).trim() : undefined,
      contact1_telephone: row['T√©l√©phone contact 1'] ? String(row['T√©l√©phone contact 1']).trim() : undefined,
      contact2_nom: row['Contact 2'] ? String(row['Contact 2']).trim() : undefined,
      contact2_telephone: row['T√©l√©phone contact 2'] ? String(row['T√©l√©phone contact 2']).trim() : undefined,

      // Informations bancaires
      banque_institution: row['Compte bancaire CA - Institution'] ? String(row['Compte bancaire CA - Institution']).trim() : undefined,
      banque_transit: row['Compte bancaire CA - Transit'] ? String(row['Compte bancaire CA - Transit']).trim() : undefined,
      banque_compte: row['Compte bancaire CA - Num√©ro de compte'] ? String(row['Compte bancaire CA - Num√©ro de compte']).trim() : undefined,

      // Informations financi√®res
      capital_origine: parseAmount(row['Capital d\'origine']),
      montant_paiement: parseAmount(row['Montant des paiements (Original)']),
      frequence_paiement: row['Fr√©quence des paiements (Originale)(incluant jours)'] ? String(row['Fr√©quence des paiements (Originale)(incluant jours)']).trim() : undefined,

      // √âtat du dossier
      etat_dossier: row['√âtat du Dossier'] ? String(row['√âtat du Dossier']).trim() : undefined,
      responsable_dossier: row['Responsable du Dossier'] ? String(row['Responsable du Dossier']).trim() : undefined,
      date_creation_dossier: parseDate(row['Date de cr√©ation du Dossier']),
      date_maj_dossier: parseDate(row['Derni√®re mise √† jour du Dossier']),

      // Statistiques de paiement
      total_paiements_positifs: parseAmount(row['Total des paiements Positifs (Pr√™t complet)']),
      total_paiements_negatifs: parseAmount(row['Total des paiements N√©gatifs (Pr√™t complet)']),
      nombre_paiements_faits: parseInteger(row['Nombre d\'occurrences de Pmt fait (tous) (pour p√©riode)']),
      nombre_paiements_non_payes: parseInteger(row['Nombre d\'occurrences de Pmt non pay√© (tous) (pour p√©riode)']),
      nombre_mauvaises_creances: parseInteger(row['Nombre d\'occurrences des Mauvaises cr√©ances (pour p√©riode)']),

      // Soldes
      solde_actuel: parseAmount(row['Solde √† Date Fin rapport']),
      solde_capital_recevoir: parseAmount(row['Solde Capital √† recevoir √† Date de Fin rapport']),

      // Dates de paiement
      date_premier_paiement: parseDate(row['Premi√®re transaction positive - Date']),
      date_dernier_paiement: parseDate(row['Derni√®re transaction positive - Date']),
      montant_dernier_paiement: parseAmount(row['Derni√®re transaction positive - Montant']),
      etat_dernier_paiement: row['Dernier paiement Pay√© (tous √âtats de ligne Pay√©)(Pr√™t complet) - √âtat de ligne'] ? String(row['Dernier paiement Pay√© (tous √âtats de ligne Pay√©)(Pr√™t complet) - √âtat de ligne']).trim() : undefined,

      // IBV
      lien_ibv: row['Lien IBV'] ? String(row['Lien IBV']).trim() : undefined,

      // Flags de fraude
      flag_pas_ibv: !row['Lien IBV'] || String(row['Lien IBV']).trim() === '',
      flag_mauvaise_creance: parseInteger(row['Nombre d\'occurrences des Mauvaises cr√©ances (pour p√©riode)']) > 0,
      flag_paiement_rate_precoce: false, // Calcul√© apr√®s
      flag_documents_email: false
    }

    // Calculer flag_paiement_rate_precoce
    if (client.nombre_paiements_non_payes && client.nombre_paiements_faits) {
      const totalPaiements = client.nombre_paiements_non_payes + client.nombre_paiements_faits
      if (totalPaiements > 0 && client.nombre_paiements_non_payes > 0) {
        // Si rat√© dans les 3 premiers paiements
        if (client.nombre_paiements_faits <= 3) {
          client.flag_paiement_rate_precoce = true
        }
      }
    }

    return client
  } catch (error: any) {
    console.warn(`‚ö†Ô∏è  Erreur transformation client: ${error.message}`)
    return null
  }
}

// ================== INSERTION SUPABASE ==================
async function insertBatch(clients: ClientSAR[], batchIndex: number, totalBatches: number): Promise<{ inserted: number, errors: number }> {
  const startTime = Date.now()

  try {
    if (DRY_RUN) {
      console.log(`   Lot ${batchIndex}/${totalBatches} (${clients.length} clients)... üß™ DRY-RUN (simulation)`)
      return { inserted: clients.length, errors: 0 }
    }

    // D√©-dupliquer dans le lot
    const uniqueClients = Array.from(
      new Map(clients.map(c => [c.margill_id, c])).values()
    )

    if (uniqueClients.length < clients.length) {
      console.log(`   ‚ö†Ô∏è  Lot ${batchIndex}: ${clients.length - uniqueClients.length} duplicates internes supprim√©s`)
    }

    const { data, error } = await supabase
      .from('clients_sar')
      .upsert(uniqueClients, {
        onConflict: 'margill_id',
        ignoreDuplicates: SKIP_DUPLICATES
      })

    if (error) {
      console.log(`   Lot ${batchIndex}/${totalBatches} (${uniqueClients.length} clients)... ‚ùå Erreur`)
      console.log(error)
      return { inserted: 0, errors: uniqueClients.length }
    }

    const duration = Date.now() - startTime
    console.log(`   Lot ${batchIndex}/${totalBatches} (${uniqueClients.length} clients)... ‚úÖ (${duration}ms)`)
    return { inserted: uniqueClients.length, errors: 0 }
  } catch (error: any) {
    console.log(`   Lot ${batchIndex}/${totalBatches}... ‚ùå Exception: ${error.message}`)
    return { inserted: 0, errors: clients.length }
  }
}

// ================== V√âRIFICATION DATAFLOW ==================
async function verifyDataflow() {
  console.log('\nüîç V√âRIFICATION DU DATAFLOW\n')

  const checks = []

  // Check 1: Connexion Supabase
  try {
    const { data, error } = await supabase.from('clients_sar').select('count', { count: 'exact', head: true })
    if (error) throw error
    checks.push({ check: 'Connexion Supabase', status: '‚úÖ', details: 'OK' })
  } catch (e: any) {
    checks.push({ check: 'Connexion Supabase', status: '‚ùå', details: e.message })
  }

  // Check 2: Fichier XLSX existe
  try {
    if (!fs.existsSync(xlsxFilePath)) throw new Error('Fichier introuvable')
    const stats = fs.statSync(xlsxFilePath)
    checks.push({ check: 'Fichier XLSX', status: '‚úÖ', details: `${(stats.size / 1024 / 1024).toFixed(2)} MB` })
  } catch (e: any) {
    checks.push({ check: 'Fichier XLSX', status: '‚ùå', details: e.message })
  }

  // Check 3: Python disponible
  try {
    const { execSync } = require('child_process')
    const version = execSync('python3 --version', { encoding: 'utf-8' }).trim()
    checks.push({ check: 'Python3', status: '‚úÖ', details: version })
  } catch (e: any) {
    checks.push({ check: 'Python3', status: '‚ùå', details: 'Non disponible' })
  }

  // Check 4: openpyxl disponible
  try {
    const { execSync } = require('child_process')
    execSync('python3 -c "import openpyxl"', { encoding: 'utf-8' })
    checks.push({ check: 'openpyxl', status: '‚úÖ', details: 'Install√©' })
  } catch (e: any) {
    checks.push({ check: 'openpyxl', status: '‚ùå', details: 'Non install√©' })
  }

  // Afficher les r√©sultats
  checks.forEach(({ check, status, details }) => {
    console.log(`${status} ${check}: ${details}`)
  })

  const allPassed = checks.every(c => c.status === '‚úÖ')
  console.log(`\n${allPassed ? '‚úÖ' : '‚ùå'} V√©rification dataflow: ${allPassed ? 'PASSED' : 'FAILED'}`)

  return allPassed
}

// ================== MAIN ==================
async function main() {
  console.log('üöÄ IMPORT CLIENTS SAR DEPUIS XLSX')
  console.log('=' .repeat(60))
  console.log(`üìÅ Fichier: ${xlsxFilePath}`)
  console.log(`üè¢ Supabase: ${supabaseUrl}`)
  console.log(`üì¶ Taille des lots: ${BATCH_SIZE}`)
  console.log(`üß™ Mode dry-run: ${DRY_RUN ? 'OUI' : 'NON'}`)
  console.log(`üîÑ Skip duplicates: ${SKIP_DUPLICATES ? 'OUI' : 'NON'}`)
  console.log('=' .repeat(60))

  // V√©rification pr√©alable
  const dataflowOK = await verifyDataflow()
  if (!dataflowOK) {
    console.error('\n‚ùå V√©rification dataflow √©chou√©e. Arr√™t.')
    process.exit(1)
  }

  try {
    // √âTAPE 1: Lecture XLSX
    const records = await readXLSX()

    // √âTAPE 2: Transformation
    console.log('\nüîÑ √âTAPE 2: Transformation des donn√©es...')
    const startTransform = Date.now()
    const clients = records
      .map(transformClient)
      .filter((c): c is ClientSAR => c !== null)

    logPipelineStep(
      'Transformation',
      records.length,
      clients.length,
      records.length - clients.length,
      startTransform,
      {
        'Lignes invalides': records.length - clients.length,
        'Taux de succ√®s': `${((clients.length / records.length) * 100).toFixed(1)}%`
      }
    )

    // Statistiques de fraude
    const statsIBV = clients.filter(c => c.flag_pas_ibv).length
    const statsMauvaisCreance = clients.filter(c => c.flag_mauvaise_creance).length
    const statsPaiementRatePrecoce = clients.filter(c => c.flag_paiement_rate_precoce).length
    const withDossierId = clients.filter(c => c.dossier_id).length

    console.log('\nüìä Statistiques de fraude d√©tect√©es:')
    console.log(`   - Sans IBV: ${statsIBV} (${((statsIBV / clients.length) * 100).toFixed(1)}%)`)
    console.log(`   - Mauvaises cr√©ances: ${statsMauvaisCreance} (${((statsMauvaisCreance / clients.length) * 100).toFixed(1)}%)`)
    console.log(`   - Paiement rat√© pr√©coce: ${statsPaiementRatePrecoce} (${((statsPaiementRatePrecoce / clients.length) * 100).toFixed(1)}%)`)
    console.log(`   - Avec N¬∞ contrat (MC): ${withDossierId} (${((withDossierId / clients.length) * 100).toFixed(1)}%)`)

    // √âTAPE 3: Insertion dans Supabase
    console.log('\nüíæ √âTAPE 3: Insertion dans Supabase...')
    const startInsert = Date.now()

    let totalInserted = 0
    let totalErrors = 0

    // Diviser en lots
    const batches: ClientSAR[][] = []
    for (let i = 0; i < clients.length; i += BATCH_SIZE) {
      batches.push(clients.slice(i, i + BATCH_SIZE))
    }

    // Ins√©rer lot par lot
    for (let i = 0; i < batches.length; i++) {
      const result = await insertBatch(batches[i], i + 1, batches.length)
      totalInserted += result.inserted
      totalErrors += result.errors

      // Petit d√©lai entre les lots pour √©viter la surcharge
      if (i < batches.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 100))
      }
    }

    logPipelineStep(
      'Insertion Supabase',
      clients.length,
      totalInserted,
      totalErrors,
      startInsert,
      {
        'Batches': batches.length,
        'Taux de succ√®s': `${((totalInserted / clients.length) * 100).toFixed(1)}%`
      }
    )

    // R√âSUM√â FINAL
    console.log('\n' + '='.repeat(60))
    console.log('üìä R√âSULTATS DE L\'IMPORT')
    console.log('='.repeat(60))
    console.log(`   ‚úÖ Ins√©r√©s: ${totalInserted}`)
    console.log(`   ‚ùå Erreurs: ${totalErrors}`)
    console.log(`   üìà Taux de succ√®s: ${((totalInserted / clients.length) * 100).toFixed(1)}%`)

    // Trace compl√®te du pipeline
    console.log('\nüìã TRACE DU PIPELINE:')
    console.log('='.repeat(60))
    pipelineTrace.forEach((step, idx) => {
      console.log(`\n${idx + 1}. ${step.step}`)
      console.log(`   Input: ${step.input} | Output: ${step.output} | Errors: ${step.errors}`)
      console.log(`   Duration: ${step.duration}ms`)
      if (step.details) {
        Object.entries(step.details).forEach(([key, val]) => {
          console.log(`   ${key}: ${JSON.stringify(val)}`)
        })
      }
    })

    // Sauvegarder la trace
    const traceFile = '/tmp/import-trace.json'
    fs.writeFileSync(traceFile, JSON.stringify(pipelineTrace, null, 2))
    console.log(`\nüíæ Trace sauvegard√©e: ${traceFile}`)

    console.log('\n‚úÖ Import termin√©!')

  } catch (error: any) {
    console.error('\n‚ùå Erreur fatale:', error)
    console.error(error.stack)
    process.exit(1)
  }
}

// Ex√©cution
main()
